apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-airflow-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: backend-airflow-scheduler
  template:
    metadata:
      labels:
        app: backend-airflow-scheduler
    spec:
      imagePullSecrets:
      {{- toYaml .Values.imagePullSecrets | nindent 8 }}
      initContainers:
      - name: airflow-db-init
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command: ["airflow", "db", "init"]
        env:
          - name: AIRFLOW__CORE__FERNET_KEY
            value: {{ .Values.airflow.fernetKey | quote }}
          - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
            value: {{ .Values.airflow.dbConnection | quote }}
      containers:
        - name: scheduler
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["airflow", "scheduler"]
          env:
            - name: AIRFLOW__CORE__FERNET_KEY
              value: {{ .Values.airflow.fernetKey | quote }}
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: {{ .Values.airflow.dbConnection | quote }}
            - name: AIRFLOW__CORE__EXECUTOR
              value: "SequentialExecutor"
          # --- NUEVA SECCIÓN: MONTURA DE VOLUMEN ---
          volumeMounts:
            - name: shared-data
              # Montamos el disco en la ruta que usan tus DAGs para guardar los datos.
              mountPath: /opt/airflow/data
      # --- NUEVA SECCIÓN: DEFINICIÓN DEL VOLUMEN ---
      volumes:
        - name: shared-data
          persistentVolumeClaim:
            # Apuntamos al PVC con el nombre fijo que creamos en el chart common.
            claimName: shared-data-pvc
